# Revised Deployment Plan: Hybrid Cloud + Local Resilience

## Architecture Overview

| Component | Cloud Deployment | Local Offline Instance | Sync Strategy |
| --------- | ---------------- | ---------------------- | ------------- |
| Frontend | Vercel | Local SvelteKit build | Service Worker + IndexedDB |
| Backend | Render | Local FastAPI (Docker) | REST API sync |
| Database | Neon | Local PostgreSQL (Docker) | Bidirectional sync |
| LLM | Groq API | Ollama (local) | Fallback routing |

## Key Changes Needed

### 1. **Database Schema Modifications for Sync**

Add these tables to the existing schema:

```sql
-- Add to migrations
CREATE TABLE sync_metadata (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    entity_type VARCHAR(50) NOT NULL,  -- 'document', 'user', 'update'
    entity_id UUID NOT NULL,
    last_modified TIMESTAMPTZ DEFAULT NOW(),
    sync_version INTEGER DEFAULT 1,
    instance_id UUID NOT NULL,
    is_deleted BOOLEAN DEFAULT FALSE,
    cloud_synced BOOLEAN DEFAULT FALSE,
    local_synced BOOLEAN DEFAULT FALSE
);

CREATE TABLE sync_log (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    instance_id UUID NOT NULL,
    sync_timestamp TIMESTAMPTZ DEFAULT NOW(),
    direction VARCHAR(10) CHECK (direction IN ('push', 'pull')),
    entities_count INTEGER DEFAULT 0,
    success BOOLEAN DEFAULT TRUE
);
```

### 2. **Backend Sync Endpoints**

Add to the FastAPI backend:

```python
# backend/app/sync.py
from pydantic import BaseModel
from typing import List, Optional

class SyncChange(BaseModel):
    entity_type: str
    entity_id: UUID
    operation: str  # 'create', 'update', 'delete'
    data: Optional[dict]
    last_modified: datetime

class SyncPayload(BaseModel):
    instance_id: UUID
    changes: List[SyncChange]
    last_sync: Optional[datetime]

@app.post("/api/sync/push")
async def push_changes(payload: SyncPayload, api_key: str = Depends(verify_sync_key)):
    # Apply changes to cloud database
    # Return conflicts for manual resolution
    
@app.get("/api/sync/pull")
async def pull_changes(last_sync: Optional[datetime] = None):
    # Return changes since last_sync
```

### 3. **Dual LLM Provider Strategy**

Modify the LLM service to support fallback:

```python
# backend/services/llm_service.py
class DualLLMService:
    def __init__(self):
        self.cloud_client = GroqClient()
        self.local_client = OllamaClient()
        self.use_local = False
        
    async def generate_response(self, prompt: str) -> str:
        if self.use_local or not await self._check_cloud_connectivity():
            return await self.local_client.generate(prompt)
        else:
            try:
                return await self.cloud_client.generate(prompt)
            except ConnectionError:
                self.use_local = True
                return await self.local_client.generate(prompt)
```

### 4. **Local Deployment Configuration**

Create `docker-compose.local.yml`:

```yaml
version: '3.8'
services:
  database:
    image: ankane/pgvector:latest
    environment:
      POSTGRES_DB: community_resilience
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./seed_data:/docker-entrypoint-initdb.d

  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.local
    environment:
      DATABASE_URL: postgresql://postgres:postgres@database:5432/community_resilience
      OLLAMA_URL: http://ollama:11434
      SYNC_ENABLED: true
      SYNC_SERVER_URL: ${CLOUD_BACKEND_URL}
      SYNC_API_KEY: ${SYNC_API_KEY}
      DEPLOYMENT_MODE: local
    ports:
      - "8000:8000"
    depends_on:
      - database
      - ollama

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile.local
    ports:
      - "3000:3000"
    depends_on:
      - backend

volumes:
  postgres_data:
  ollama_data:
```

### 5. **Frontend Offline-First Strategy**

Add service worker and sync logic:

```javascript
// frontend/src/lib/offline.js
export class OfflineManager {
    constructor() {
        this.pendingChanges = [];
        this.isOnline = navigator.onLine;
        this.setupEventListeners();
    }
    
    async queueChange(change) {
        this.pendingChanges.push(change);
        await this.saveToIndexedDB('pending_changes', this.pendingChanges);
        
        if (this.isOnline) {
            await this.syncChanges();
        }
    }
    
    async syncChanges() {
        const changes = await this.getPendingChanges();
        if (changes.length > 0) {
            try {
                await fetch('/api/sync/push', {
                    method: 'POST',
                    body: JSON.stringify({ changes })
                });
                await this.clearPendingChanges();
            } catch (error) {
                console.error('Sync failed:', error);
            }
        }
    }
}
```

## Revised Deployment Steps

### Phase 1: Enhanced Cloud Deployment (The Current Plan + Sync)

1. **Deploy to cloud as planned** but add sync endpoints
2. **Generate sync API key** for local instances
3. **Test cloud functionality** remains unchanged

### Phase 2: Local Instance Deployment

1. **Create local Docker setup** with the compose file above
2. **Build local frontend/backend images**
3. **One-click deployment script** for non-technical users

```bash
#!/bin/bash
# deploy-local.sh
echo "Setting up local resilience hub instance..."

# Pull latest cloud data
curl -X POST "https://your-cloud-backend.com/api/sync/export" \
  -H "Authorization: Bearer $SYNC_API_KEY" \
  -o latest_data.sql

# Start local services
docker-compose -f docker-compose.local.yml up -d

# Wait for services to be ready
sleep 30

# Import initial data
docker exec local_backend alembic upgrade head
docker exec local_backend python scripts/load_initial_data.py

echo "Local instance ready at http://localhost:3000"
```

### Phase 3: Sync Strategy Implementation

1. **Background sync service** that runs every 15 minutes when online
2. **Conflict resolution UI** for manual review
3. **Selective sync** to avoid syncing large files unnecessarily

## Cost Analysis - Still Free Tier Friendly

| Service | Cloud | Local | Cost |
| ------- | ----- | ----- | ---- |
| **Database** | Neon (free) | PostgreSQL Docker (free) | $0 |
| **LLM** | Groq (free) | Ollama (free) | $0 |
| **Backend** | Render (free) | Local Docker (free) | $0 |
| **Frontend** | Vercel (free) | Local build (free) | $0 |

## Emergency Operation Protocol

### Normal Operation (Online)

- Local instance syncs with cloud every 15 minutes
- Uses Groq API for faster responses
- All changes bidirectional

### Emergency Mode (Offline)

- Local instance operates independently
- Uses Ollama for LLM capabilities
- Queues changes for later sync
- Full functionality maintained

### Recovery (Back Online)

- Automatic conflict detection
- Manual resolution interface
- Batch sync operations

## Implementation Priority

1. **Week 1**: Add sync endpoints to existing cloud deployment
2. **Week 2**: Create local Docker setup
3. **Week 3**: Implement frontend offline capabilities
4. **Week 4**: Test and refine sync protocol

This approach maintains your free-tier cloud deployment while adding robust offline capability. The local instance can be deployed on any computer (even a Raspberry Pi) and will automatically sync when connectivity is available.

Would you like me to elaborate on any specific component or provide the detailed implementation code for particular sections?
