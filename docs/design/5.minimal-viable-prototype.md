# Minimum Viable Prototype

## 1. Scope the MVP

**Goal:** Support *one* clear use case end‑to‑end, not the whole lifecycle.

I’d pick:

> **Use case:** Help a community coordinator prioritize needs and actions during a flood using local knowledge.

That’s concrete, high‑impact, and tests the core reasoning loop.

---

## 2. Minimal architecture for the MVP

| Layer | What it is in the MVP | How “small” we keep it |
| ---- | ---------------------- | ----------------------- |
| Data | A tiny local knowledge base | 20–50 curated entries |
| Memory | Simple vector store + tags | No full knowledge graph yet |
| Reasoning | One general LLM with structured prompts | No fine‑tuning initially |
| Interface | Single web form or chat UI | Text in, text out |
| Feedback | Manual rating/comments | No automated learning loop yet |

---

## 3. Step-by-step build

### 3.1 Create a tiny community knowledge base

- **Format:** A simple table or JSON file with entries like:
  - **Location:** “Riverside Street”
  - **Issue:** “Floods after 100mm rain”
  - **Impact:** “Elderly residents stranded”
  - **Resources:** “Community hall on Hilltop Road used as shelter”
- Aim for:
  - **Past events:** 5–10 short narratives.
  - **Key places:** shelters, risky roads, critical services.
  - **Vulnerable groups:** elderly, people with disabilities, isolated households.

## 3.2 Add basic retrieval

- Use embeddings + a small vector store (e.g., local or hosted).
- When the user types a situation:
  - “Heavy rain, Riverside Street already underwater, power out.”
  - Retrieve the top 3–5 most relevant knowledge entries.

### 3.3 Wrap a reasoning model around it

- Use a general LLM (no fine‑tuning yet).
- Prompt pattern:

  > **System:** You are a disaster response assistant using local community knowledge. Always reason step by step and prioritize safety and equity.  
  > **Context (retrieved knowledge):**  
  > – Riverside Street floods after 100mm rain; elderly residents often stranded.  
  > – Hilltop Community Hall is a known safe shelter with backup generator.  
  > **User:** Heavy rain, Riverside Street already underwater, power out. What should we prioritize?

- Ask the model to output:
  - A short **situation summary**.
  - A **ranked list of 3–5 actions**.
  - A brief **rationale** for each action.

### 3.4 Simple interface

- A minimal web page or chat UI with:
  - **Input box:** “Describe what’s happening.”
  - **Optional dropdowns/tags:** hazard type, location.
  - **Output area:** summary + prioritized actions.

---

## 4. Feedback loop (manual, but important)

After each use:

- The coordinator marks:
  - **Useful / partly useful / not useful.**
  - Optional comment: “Missed that the bridge is out,” “Good, but shelter is full,” etc.
- You log:
  - Input description.
  - Retrieved knowledge.
  - Model output.
  - Human feedback.

This becomes our **first real dataset** for improving prompts, knowledge structure, and later fine‑tuning.

---

## 5. What this MVP *proves*

If it works even halfway decently, you’ve shown that:

- Local knowledge + a reasoning model can produce **context‑aware, actionable suggestions**.
- Community coordinators can **interact with it naturally**.
- our can start to see **where the gaps are**: missing data, bad retrieval, unclear prompts.

From there, we can decide whether the next iteration should be:

- Richer knowledge representation (e.g., a small knowledge graph),  
- More tasks (preparedness, recovery), or  
- Better reasoning (fine‑tuning, tool use, constraints).
